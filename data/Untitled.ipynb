{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from rand_augmentation import RandAugment\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from rand_augmentation import RandAugment\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def default_image_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class RandaugLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, rootdir, transform=None, loader=default_image_loader):\n",
    "        self.impath = os.path.join(rootdir, 'train/train_data')\n",
    "        meta_file = os.path.join(rootdir, 'train/train_label')\n",
    "\n",
    "        imnames = []\n",
    "\n",
    "        os.lists()\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.imnames = imnames\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.imnames[index]\n",
    "        img = self.loader(os.path.join(self.impath, filename))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_transformed = self.transform(img)\n",
    "        return img, img_transformed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imnames)\n",
    "def main():\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        RandaugLoader('/home/dykim/cs492/data/images', list(range(21)),\n",
    "                            transform=transforms.Compose([\n",
    "                                RandAugment(2, 3) if opts.use_randaug else lambda x: x,\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
    "                                #transforms.ToTensor(),\n",
    "                            #    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                            ])),\n",
    "        batch_size=5, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "    print('train_loader done')\n",
    "\n",
    "    for i  in range(len(train_loader)): # 4\n",
    "        for j in range(train_loader.batch_size): # 5\n",
    "            img, img_transformed = next(train_loader)\n",
    "\n",
    "            plt.subplot(len(train_loader), len(train_loader.batch_size)*2, i*len(train_loader.batch_size)*2+j*2+1)\n",
    "            plt.imshow(img)\n",
    "\n",
    "            plt.subplot(len(train_loader), len(train_loader.batch_size) * 2, i*len(train_loader.batch_size)*2+j*2+2)\n",
    "            plt.imshow(img_transformed)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3",
   "language": "python",
   "name": "pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
